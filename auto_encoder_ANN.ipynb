{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "from nengo.utils.matplotlib import rasterplot\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import nengo_dl\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "tf.get_logger().addFilter(lambda rec: \"Tracing is expensive\" not in rec.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# download MNIST dataset\n",
    "(train_data, _), (test_data, _) = tf.keras.datasets.mnist.load_data()\n",
    "# flatten images\n",
    "train_data = train_data.reshape((train_data.shape[0], -1))\n",
    "test_data = test_data.reshape((test_data.shape[0], -1))\n",
    "\n",
    "n_epochs = 2\n",
    "n_in = train_data.shape[1]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophesee dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.io.psee_loader import PSEELoader\n",
    "\n",
    "import pathlib\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 10000, 900) (15, 10000, 900)\n"
     ]
    }
   ],
   "source": [
    "delta_t = 10000\n",
    "n = 75\n",
    "skip = 100\n",
    "\n",
    "vids = map(PSEELoader, glob(\"Prophesee_Dataset_n_cars/n-cars_train/cars/*_td.dat\"))\n",
    "# height, width = vid.get_size()\n",
    "height, width = 120, 120\n",
    "# vid.seek_time(skip)\n",
    "event_seqs = [next(vids).load_delta_t(delta_t) for _ in range(n)]\n",
    "# N = len(event_seqs)\n",
    "\n",
    "#print(event_seqs[0])\n",
    "\n",
    "dat = np.zeros((n, delta_t, 30, 30),dtype=np.int8)\n",
    "for i,block in enumerate(event_seqs):\n",
    "    for ev in block:\n",
    "        dat[i,ev[0],ev[1]//4,ev[2]//4] = ev[3]\n",
    "# for ev in events:\n",
    "#     dat[ev[0],ev[1],ev[2]] = ev[3]\n",
    "\n",
    "# dat = decimate(dat,4,axis=2)\n",
    "# dat = decimate(dat,4,axis=3)\n",
    "\n",
    "train_data = dat[0:60,:,:,:]\n",
    "test_data  = dat[60:75,:,:,:]\n",
    "\n",
    "train_data = train_data.reshape((train_data.shape[0], train_data.shape[1], -1))\n",
    "test_data = test_data.reshape((test_data.shape[0], test_data.shape[1], -1))\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Implementation of Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "n_hidden = 64\n",
    "minibatch_size = 8\n",
    "\n",
    "class auto_enc_tf(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(n_hidden, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(n_in, activation=tf.nn.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    return self.dense2(x)\n",
    "\n",
    "  def hidden_rep(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    y = self.dense2(x)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 20:18:23.814124: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 514.98MiB (rounded to 540000000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-03-06 20:18:23.814255: W tensorflow/core/common_runtime/bfc_allocator.cc:474] ***************************************************************************************************x\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mRMSprop(\u001b[39m1e-3\u001b[39m), loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mmse)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# run training loop\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_data, train_data, epochs\u001b[39m=\u001b[39;49mn_epochs, batch_size\u001b[39m=\u001b[39;49mminibatch_size)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=6'>7</a>\u001b[0m \u001b[39m# evaluate performance on test set\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m#model.evaluate(test_data, test_data)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m \u001b[39m# display example output\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2267617573732e6563652e756373622e656475222c2275736572223a226b61727468696b227d/home/karthik/sim_clean/ece_594bb/ece594bb_pl-proj/auto_encoder_ANN.ipynb#ch0000004vscode-remote?line=10'>11</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_data[[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[0;32m~/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=103'>104</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=104'>105</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> <a href='file:///home/karthik/miniconda3/envs/neuromorphic/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py?line=105'>106</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model = auto_enc_tf()\n",
    "model.compile(optimizer=tf.optimizers.RMSprop(1e-3), loss=tf.losses.mse)\n",
    "\n",
    "# run training loop\n",
    "model.fit(train_data, train_data, epochs=n_epochs, batch_size=minibatch_size)\n",
    "\n",
    "# evaluate performance on test set\n",
    "#model.evaluate(test_data, test_data)\n",
    "\n",
    "# display example output\n",
    "output = model.predict(test_data[[0]])\n",
    "plt.figure()\n",
    "plt.imshow(output[0].reshape((28, 28)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hidden latent representation of normal 1 hidden layer ANN auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the hidden space rep: 0.09524098\n"
     ]
    }
   ],
   "source": [
    "hidden_rep = model.hidden_rep(test_data[[0]])\n",
    "plt.figure()\n",
    "plt.imshow(hidden_rep[0].numpy().reshape((8, 8)))\n",
    "plt.show()\n",
    "\n",
    "hidden_rep = hidden_rep[0].numpy()\n",
    "norm = np.linalg.norm(hidden_rep)\n",
    "hidden_rep = hidden_rep/norm\n",
    "print('Mean of the hidden space rep:', hidden_rep.mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f33ad4317645b163532d34963980873b1273d47e12dd0b5aad2c9d3af0e6882a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('neuromorphic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
